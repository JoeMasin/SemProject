{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic estimation of Ejection Fraction from echocardiographic images using the Simpson's biplane method of disks\n",
    "===\n",
    "\n",
    "***\n",
    "# <span style=\"color:brown\"> Preamble\n",
    "\n",
    "This notebook provides a method to compute the ejection fraction from Simpson's biplane method of disks using the segmentation obtained from 2D echocardiographic images at end diastole and end systole time instances from Apical two and four chambers views. This method was used in the following paper:\n",
    "\n",
    "Leclerc S, Smistad E, Pedrosa J, Østvik A, Cervenansky F, Espinosa F, Espeland T, Rye Berg EA, Jodoin PM, Grenier T, Lartizien C, D’hooge J, Lovstakken L, Bernard O. \"Deep Learning for Segmentation using an Open Large-Scale Dataset in 2D Echocardiography\" IEEE Trans Med Imaging, 2019:38:2198-2210, DOI: 10.1109/TMI.2019.2900516\n",
    "    \n",
    "# <span style=\"color:brown\"> Objectives\n",
    "\n",
    "* Provide the code to compute EF for open science purposes \n",
    "* This code can be run from the [CAMUS dataset](https://humanheart-project.creatis.insa-lyon.fr/database/#collection/6373703d73e9f0047faa1bc8) to reproduce the EF values provided in this collection\n",
    "    \n",
    "***\n",
    "\n",
    "# <span style=\"color:brown\"> Warnings\n",
    "\n",
    "* We have observed that the way in which Simpson's biplane method is implemented can have a significant influence on the final values calculated. We do not guarantee that the method implemented in this notebook is optimal. The values produced by this method should be used with caution.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the different python librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import SimpleITK as sitk\n",
    "from PIL.Image import Resampling\n",
    "from skimage.measure import find_contours\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define a few useful functions to load and manipulate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sitk_load(filepath: str | Path) -> Tuple[np.ndarray, Dict[str, Any]]:\n",
    "    \"\"\"Loads an image using SimpleITK and returns the image and its metadata.\n",
    "\n",
    "    Args:\n",
    "        filepath: Path to the image.\n",
    "\n",
    "    Returns:\n",
    "        - ([N], H, W), Image array.\n",
    "        - Collection of metadata.\n",
    "    \"\"\"\n",
    "    # Load image and save info\n",
    "    image = sitk.ReadImage(str(filepath))\n",
    "    info = {\"origin\": image.GetOrigin(), \"spacing\": image.GetSpacing(), \"direction\": image.GetDirection()}\n",
    "\n",
    "    # Extract numpy array from the SimpleITK image object\n",
    "    im_array = np.squeeze(sitk.GetArrayFromImage(image))\n",
    "\n",
    "    return im_array, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize_image(image: np.ndarray, size: Tuple[int, int], resample: Resampling = Resampling.NEAREST) -> np.ndarray:\n",
    "    \"\"\"Resizes the image to the specified dimensions.\n",
    "\n",
    "    Args:\n",
    "        image: (H, W), Input image to resize. Must be in a format supported by PIL.\n",
    "        size: Width (W') and height (H') dimensions of the resized image to output.\n",
    "        resample: Resampling filter to use.\n",
    "\n",
    "    Returns:\n",
    "        (H', W'), Input image resized to the specified dimensions.\n",
    "    \"\"\"\n",
    "    resized_image = np.array(PIL.Image.fromarray(image).resize(size, resample=resample))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize_image_to_isotropic(\n",
    "    image: np.ndarray, spacing: Tuple[float, float], resample: Resampling = Resampling.NEAREST\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Resizes the image to attain isotropic spacing, by resampling the dimension with the biggest voxel size.\n",
    "\n",
    "    Args:\n",
    "        image: (H, W), Input image to resize. Must be in a format supported by PIL.\n",
    "        spacing: Size of the image's pixels along each (height, width) dimension.\n",
    "        resample: Resampling filter to use.\n",
    "\n",
    "    Returns:\n",
    "        (H', W'), Input image resized so that the spacing is isotropic, and the isotropic value of the new spacing.\n",
    "    \"\"\"\n",
    "    scaling = np.array(spacing) / min(spacing)\n",
    "    new_height, new_width = (np.array(image.shape) * scaling).round().astype(int)\n",
    "    return resize_image(image, (new_width, new_height), resample=resample), min(spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Simpson's biplane method of disks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_left_ventricle_volumes(\n",
    "    a2c_ed: np.ndarray,\n",
    "    a2c_es: np.ndarray,\n",
    "    a2c_voxelspacing: Tuple[float, float],\n",
    "    a4c_ed: np.ndarray,\n",
    "    a4c_es: np.ndarray,\n",
    "    a4c_voxelspacing: Tuple[float, float],\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Computes the ED and ES volumes of the left ventricle from 2 orthogonal 2D views (A2C and A4C).\n",
    "\n",
    "    Args:\n",
    "        a2c_ed: (H,W), Binary segmentation map of the left ventricle from the end-diastole (ED) instant of the 2-chamber\n",
    "            apical view (A2C).\n",
    "        a2c_es: (H,W), Binary segmentation map of the left ventricle from the end-systole (ES) instant of the 2-chamber\n",
    "            apical view (A2C).\n",
    "        a2c_voxelspacing: Size (in mm) of the 2-chamber apical view's voxels along each (height, width) dimension.\n",
    "        a4c_ed: (H,W), Binary segmentation map of the left ventricle from the end-diastole (ED) instant of the 4-chamber\n",
    "            apical view (A4C).\n",
    "        a4c_es: (H,W), Binary segmentation map of the left ventricle from the end-systole (ES) instant of the 4-chamber\n",
    "            apical view (A4C).\n",
    "        a4c_voxelspacing: Size (in mm) of the 4-chamber apical view's voxels along each (height, width) dimension.\n",
    "\n",
    "    Returns:\n",
    "        Left ventricle ED and ES volumes.\n",
    "    \"\"\"\n",
    "    for mask_name, mask in [(\"a2c_ed\", a2c_ed), (\"a2c_es\", a2c_es), (\"a4c_ed\", a4c_ed), (\"a4c_es\", a4c_es)]:\n",
    "        if mask.max() > 1:\n",
    "            logger.warning(\n",
    "                f\"`compute_left_ventricle_volumes` expects binary segmentation masks of the left ventricle (LV). \"\n",
    "                f\"However, the `{mask_name}` segmentation contains a label greater than '1/True'. If this was done \"\n",
    "                f\"voluntarily, you can safely ignore this warning. However, the most likely cause is that you forgot \"\n",
    "                f\"to extract the binary LV segmentation from a multi-class segmentation mask.\"\n",
    "            )\n",
    "\n",
    "    a2c_ed_diameters, a2c_ed_step_size = _compute_diameters(a2c_ed, a2c_voxelspacing)\n",
    "    a2c_es_diameters, a2c_es_step_size = _compute_diameters(a2c_es, a2c_voxelspacing)\n",
    "    a4c_ed_diameters, a4c_ed_step_size = _compute_diameters(a4c_ed, a4c_voxelspacing)\n",
    "    a4c_es_diameters, a4c_es_step_size = _compute_diameters(a4c_es, a4c_voxelspacing)\n",
    "    step_size = max((a2c_ed_step_size, a2c_es_step_size, a4c_ed_step_size, a4c_es_step_size))\n",
    "\n",
    "    ed_volume = _compute_left_ventricle_volume_by_instant(a2c_ed_diameters, a4c_ed_diameters, step_size)\n",
    "    es_volume = _compute_left_ventricle_volume_by_instant(a2c_es_diameters, a4c_es_diameters, step_size)\n",
    "    return ed_volume, es_volume\n",
    "\n",
    "\n",
    "def _compute_left_ventricle_volume_by_instant(\n",
    "    a2c_diameters: np.ndarray, a4c_diameters: np.ndarray, step_size: float\n",
    ") -> float:\n",
    "    \"\"\"Compute left ventricle volume using Biplane Simpson's method.\n",
    "\n",
    "    Args:\n",
    "        a2c_diameters: Diameters measured at each key instant of the cardiac cycle, from the 2-chamber apical view.\n",
    "        a4c_diameters: Diameters measured at each key instant of the cardiac cycle, from the 4-chamber apical view.\n",
    "        step_size:\n",
    "\n",
    "    Returns:\n",
    "        Left ventricle volume (in millilitres).\n",
    "    \"\"\"\n",
    "    # All measures are now in millimeters, convert to meters by dividing by 1000\n",
    "    a2c_diameters /= 1000\n",
    "    a4c_diameters /= 1000\n",
    "    step_size /= 1000\n",
    "\n",
    "    # Estimate left ventricle volume from orthogonal disks\n",
    "    lv_volume = np.sum(a2c_diameters * a4c_diameters) * step_size * np.pi / 4\n",
    "\n",
    "    # Volume is now in cubic meters, so convert to milliliters (1 cubic meter = 1_000_000 milliliters)\n",
    "    return round(lv_volume * 1e6)\n",
    "\n",
    "\n",
    "def _find_distance_to_edge(\n",
    "    segmentation: np.ndarray, point_on_mid_line: np.ndarray, normal_direction: np.ndarray\n",
    ") -> float:\n",
    "    distance = 8  # start a bit in to avoid line stopping early at base\n",
    "    while True:\n",
    "        current_position = point_on_mid_line + distance * normal_direction\n",
    "\n",
    "        y, x = np.round(current_position).astype(int)\n",
    "        if segmentation.shape[0] <= y or y < 0 or segmentation.shape[1] <= x or x < 0:\n",
    "            # out of bounds\n",
    "            return distance\n",
    "\n",
    "        elif segmentation[y, x] == 0:\n",
    "            # Edge found\n",
    "            return distance\n",
    "\n",
    "        distance += 0.5\n",
    "\n",
    "\n",
    "def _distance_line_to_points(line_point_0: np.ndarray, line_point_1: np.ndarray, points: np.ndarray) -> np.ndarray:\n",
    "    # https://en.wikipedia.org/wiki/Distance_from_a_point_to_a_line\n",
    "    return np.absolute(np.cross(line_point_1 - line_point_0, line_point_0 - points)) / np.linalg.norm(\n",
    "        line_point_1 - line_point_0\n",
    "    )\n",
    "\n",
    "\n",
    "def _get_angle_of_lines_to_point(reference_point: np.ndarray, moving_points: np.ndarray) -> np.ndarray:\n",
    "    diff = moving_points - reference_point\n",
    "    return abs(np.degrees(np.arctan2(diff[:, 0], diff[:, 1])))\n",
    "\n",
    "\n",
    "def _compute_diameters(segmentation: np.ndarray, voxelspacing: Tuple[float, float]) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        segmentation: Binary segmentation of the structure for which to find the diameter.\n",
    "        voxelspacing: Size of the segmentations' voxels along each (height, width) dimension (in mm).\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "\n",
    "    # Make image isotropic, have same spacing in both directions.\n",
    "    # The spacing can be multiplied by the diameter directly.\n",
    "    segmentation, isotropic_spacing = resize_image_to_isotropic(segmentation, voxelspacing)\n",
    "\n",
    "    # Go through entire contour to find AV plane\n",
    "    contour = find_contours(segmentation, 0.5)[0]\n",
    "\n",
    "    # For each pair of contour points\n",
    "    # Check if angle is ok\n",
    "    # If angle is ok, check that almost all other contour points are above the line\n",
    "    # Or check that all points between are close to the line\n",
    "    # If so, it is accepted, select the longest stretch\n",
    "    best_length = 0\n",
    "    for point_idx in range(2, len(contour)):\n",
    "        previous_points = contour[:point_idx]\n",
    "        angles_to_previous_points = _get_angle_of_lines_to_point(contour[point_idx], previous_points)\n",
    "\n",
    "        for acute_angle_idx in np.nonzero(angles_to_previous_points <= 45)[0]:\n",
    "            intermediate_points = contour[acute_angle_idx + 1 : point_idx]\n",
    "            distance_to_intermediate_points = _distance_line_to_points(\n",
    "                contour[point_idx], contour[acute_angle_idx], intermediate_points\n",
    "            )\n",
    "            if np.all(distance_to_intermediate_points <= 8):\n",
    "                distance = np.linalg.norm(contour[point_idx] - contour[acute_angle_idx])\n",
    "                if best_length < distance:\n",
    "                    best_length = distance\n",
    "                    best_i = point_idx\n",
    "                    best_j = acute_angle_idx\n",
    "\n",
    "    mid_point = int(best_j + round((best_i - best_j) / 2))\n",
    "    # Apex is longest from midpoint\n",
    "    mid_line_length = 0\n",
    "    apex = 0\n",
    "    for i in range(len(contour)):\n",
    "        length = np.linalg.norm(contour[mid_point] - contour[i])\n",
    "        if mid_line_length < length:\n",
    "            mid_line_length = length\n",
    "            apex = i\n",
    "\n",
    "    direction = contour[apex] - contour[mid_point]\n",
    "    normal_direction = np.array([-direction[1], direction[0]])\n",
    "    normal_direction = normal_direction / np.linalg.norm(normal_direction)  # Normalize\n",
    "    diameters = []\n",
    "    for fraction in np.linspace(0, 1, 20, endpoint=False):\n",
    "        point_on_mid_line = contour[mid_point] + direction * fraction\n",
    "\n",
    "        distance1 = _find_distance_to_edge(segmentation, point_on_mid_line, normal_direction)\n",
    "        distance2 = _find_distance_to_edge(segmentation, point_on_mid_line, -normal_direction)\n",
    "        diameters.append((distance1 + distance2) * isotropic_spacing)\n",
    "\n",
    "    step_size = (mid_line_length * isotropic_spacing) / 20\n",
    "    return np.array(diameters), step_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 2D segmentation masks required to compute the left ventricular volumes and ejection fraction (EF) for one patient\n",
    "\n",
    "NOTE: The following cells assume that the `database_nifti` archive was downloaded and extracted in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# PARAMETERS TO PLAY WITH\n",
    "\n",
    "database_nifti_root = Path(\"./data\")\n",
    "lv_label = 1\n",
    "# Select the patient identification (scalar value between 1 and 500)\n",
    "patient_id = 237\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(database_nifti_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the ID and path of the patient to be loaded\n",
    "patient_name = f\"patient{patient_id:04d}\"\n",
    "patient_dir = database_nifti_root / patient_name\n",
    "gt_mask_pattern = \"{patient_name}_{view}_{instant}_gt.nii.gz\"\n",
    "print(f\"Loading data from patient folder: {patient_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = \"2CH\"\n",
    "instant = \"ED\"\n",
    "a2c_ed, a2c_info = sitk_load(patient_dir / gt_mask_pattern.format(patient_name=patient_name, view=view, instant=instant))\n",
    "a2c_voxelspacing = a2c_info[\"spacing\"][:2][::-1]    # Extract the (width,height) dimension from the metadata and order them like in the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instant = \"ES\"\n",
    "a2c_es, _ = sitk_load(patient_dir / gt_mask_pattern.format(patient_name=patient_name, view=view, instant=instant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = \"4CH\"\n",
    "instant = \"ED\"\n",
    "a4c_ed, a4c_info = sitk_load(patient_dir / gt_mask_pattern.format(patient_name=patient_name, view=view, instant=instant))\n",
    "a4c_voxelspacing = a4c_info[\"spacing\"][:2][::-1]    # Extract the (width,height) dimension from the metadata and order them like in the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instant = \"ES\"\n",
    "a4c_es, _ = sitk_load(patient_dir / gt_mask_pattern.format(patient_name=patient_name, view=view, instant=instant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simpson's biplane method of disks on the data from the selected patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract binary LV masks from the multi-class segmentation masks\n",
    "a2c_ed_lv_mask = a2c_ed == lv_label\n",
    "a2c_es_lv_mask = a2c_es == lv_label\n",
    "a4c_ed_lv_mask = a4c_ed == lv_label\n",
    "a4c_es_lv_mask = a4c_es == lv_label\n",
    "\n",
    "# Use the provided implementation to compute the LV volumes\n",
    "edv, esv = compute_left_ventricle_volumes(a2c_ed_lv_mask, a2c_es_lv_mask, a2c_voxelspacing, a4c_ed_lv_mask, a4c_es_lv_mask, a4c_voxelspacing)\n",
    "ef = round(100 * (edv - esv) / edv) # Round the computed value to the nearest integer\n",
    "\n",
    "print(f\"{patient_name=}: {ef=}, {edv=}, {esv=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "volumes = [95, 44]  # EDV, ESV\n",
    "labels = ['End Diastolic', 'End Systolic']\n",
    "colors = ['#2ca02c', '#d62728']\n",
    "\n",
    "# Create figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Volume plot\n",
    "ax1.bar(labels, volumes, color=colors)\n",
    "ax1.set_title('Left Ventricle Volumes')\n",
    "ax1.set_ylabel('Volume (mL)')\n",
    "for i, v in enumerate(volumes):\n",
    "    ax1.text(i, v+2, str(v), ha='center')\n",
    "\n",
    "# EF gauge\n",
    "ax2.set_title('Ejection Fraction')\n",
    "ax2.set_xlim(0, 100)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.axis('off')\n",
    "ax2.text(50, 0.8, f'{ef}%', ha='center', fontsize=24)\n",
    "\n",
    "# EF reference lines\n",
    "ax2.plot([0, 20], [0.2, 0.2], color='red', linewidth=10)\n",
    "ax2.plot([20, 40], [0.2, 0.2], color='orange', linewidth=10)\n",
    "ax2.plot([40, 55], [0.2, 0.2], color='green', linewidth=10)\n",
    "ax2.plot([55, 75], [0.2, 0.2], color='orange', linewidth=10)\n",
    "ax2.plot([75, 100], [0.2, 0.2], color='red', linewidth=10)\n",
    "\n",
    "ax2.text(10, 0.3, 'Severely Low', ha='center')\n",
    "ax2.text(30, 0.3, 'Low', ha='center')\n",
    "ax2.text(47.5, 0.3, 'Normal', ha='center')\n",
    "ax2.text(65, 0.3, 'High', ha='center')\n",
    "ax2.text(87.5, 0.3, 'Very High', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Create a custom colormap for overlay (red for LV segmentation)\n",
    "mask_cmap = ListedColormap([[0, 0, 0, 0], [1, 0, 0, 0.5]])  # Transparent, then semi-transparent red\n",
    "\n",
    "def load_echo_image(patient_dir, patient_name, view, instant):\n",
    "    \"\"\"Load original echocardiographic image\"\"\"\n",
    "    img_pattern = f\"{patient_name}_{view}_{instant}.nii.gz\"\n",
    "    img, _ = sitk_load(patient_dir / img_pattern)\n",
    "    return img\n",
    "\n",
    "# Load original images\n",
    "a2c_ed_img = load_echo_image(patient_dir, patient_name, \"2CH\", \"ED\")\n",
    "a2c_es_img = load_echo_image(patient_dir, patient_name, \"2CH\", \"ES\")\n",
    "a4c_ed_img = load_echo_image(patient_dir, patient_name, \"4CH\", \"ED\")\n",
    "a4c_es_img = load_echo_image(patient_dir, patient_name, \"4CH\", \"ES\")\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 20))\n",
    "fig.suptitle(f\"Patient {patient_id} - LV Segmentation Visualization\", fontsize=16)\n",
    "\n",
    "views = [\"2CH\", \"4CH\"]\n",
    "instants = [\"ED\", \"ES\"]\n",
    "images = {\n",
    "    \"2CH_ED\": a2c_ed_img,\n",
    "    \"2CH_ES\": a2c_es_img,\n",
    "    \"4CH_ED\": a4c_ed_img,\n",
    "    \"4CH_ES\": a4c_es_img\n",
    "}\n",
    "masks = {\n",
    "    \"2CH_ED\": a2c_ed_lv_mask,\n",
    "    \"2CH_ES\": a2c_es_lv_mask,\n",
    "    \"4CH_ED\": a4c_ed_lv_mask,\n",
    "    \"4CH_ES\": a4c_es_lv_mask\n",
    "}\n",
    "\n",
    "for i, (view, instant) in enumerate([(v, t) for v in views for t in instants]):\n",
    "    key = f\"{view}_{instant}\"\n",
    "    row = i * 2\n",
    "    \n",
    "    # Original image\n",
    "    axes[i, 0].imshow(images[key], cmap='gray')\n",
    "    axes[i, 0].set_title(f\"{view} {instant} - Original\")\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Segmentation mask\n",
    "    axes[i, 1].imshow(masks[key], cmap='gray')\n",
    "    axes[i, 1].set_title(f\"{view} {instant} - LV Mask\")\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    axes[i, 2].imshow(images[key], cmap='gray')\n",
    "    axes[i, 2].imshow(masks[key], cmap=mask_cmap)\n",
    "    axes[i, 2].set_title(f\"{view} {instant} - Overlay\")\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create improved colormaps\n",
    "lvendo_cmap = ListedColormap([[0, 0, 0, 0], [1, 0, 0, 0.7]])  # Solid red for ENDOcardium\n",
    "lvepi_cmap = ListedColormap([[0, 0, 0, 0], [0, 1, 0, 0.4]])    # Semi-transparent green for EPIcardium\n",
    "la_cmap = ListedColormap([[0, 0, 0, 0], [0, 0.5, 1, 0.3]])     # Light blue for LA\n",
    "\n",
    "def load_all_masks(patient_dir, patient_name, view, instant):\n",
    "    \"\"\"Load all masks with proper structure labels\"\"\"\n",
    "    mask, info = sitk_load(patient_dir / f\"{patient_name}_{view}_{instant}_gt.nii.gz\")\n",
    "    return {\n",
    "        'LVendo': mask == 1,  # Inner blood pool boundary\n",
    "        'LVepi': mask == 2,   # Outer heart wall boundary\n",
    "        'LA': mask == 3,      # Left atrium\n",
    "        'spacing': info['spacing'][:2][::-1]\n",
    "    }\n",
    "\n",
    "# Create figure with improved layout\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 20))# make 4,3 if include 4CH in views\n",
    "fig.suptitle(f\"Patient {patient_id} - Corrected LV Structure Visualization\", fontsize=16, y=0.98)\n",
    "\n",
    "views =  [\"2CH\"]#[\"2CH\", \"4CH\"] change subplots to 4,3 if add in 4CH \n",
    "instants = [\"ED\", \"ES\"]\n",
    "\n",
    "for i, (view, instant) in enumerate([(v, t) for v in views for t in instants]):\n",
    "    # Load data\n",
    "    img = load_echo_image(patient_dir, patient_name, view, instant)\n",
    "    masks = load_all_masks(patient_dir, patient_name, view, instant)\n",
    "    \n",
    "    # Column 1: Original image\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title(f\"{view} {instant}\\nOriginal Image\", pad=10)\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Column 2: Fill visualization (corrected order)\n",
    "    axes[i, 1].imshow(img, cmap='gray')\n",
    "    axes[i, 1].imshow(masks['LVepi'], cmap=lvepi_cmap)  # EPI first (outer)\n",
    "    axes[i, 1].imshow(masks['LVendo'], cmap=lvendo_cmap)  # ENDO second (inner)\n",
    "    axes[i, 1].imshow(masks['LA'], cmap=la_cmap)\n",
    "    axes[i, 1].set_title(f\"{view} {instant}\\nStructure Fills\", pad=10)\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Column 3: Corrected contour visualization\n",
    "    axes[i, 2].imshow(img, cmap='gray')\n",
    "    \n",
    "    # Plot EPI first (outer contour)\n",
    "    epi_contours = find_contours(masks['LVepi'], 0.5)\n",
    "    for contour in epi_contours:\n",
    "        axes[i, 2].plot(contour[:, 1], contour[:, 0], linewidth=2, color='lime', label='LVEpi' if i==0 else \"\")\n",
    "    \n",
    "    # Then plot ENDO (inner contour)\n",
    "    endo_contours = find_contours(masks['LVendo'], 0.5)\n",
    "    for contour in endo_contours:\n",
    "        axes[i, 2].plot(contour[:, 1], contour[:, 0], linewidth=2, color='red', label='LVEndo' if i==0 else \"\")\n",
    "    \n",
    "    # Finally plot LA\n",
    "    la_contours = find_contours(masks['LA'], 0.5)\n",
    "    for contour in la_contours:\n",
    "        axes[i, 2].plot(contour[:, 1], contour[:, 0], linewidth=2, color='cyan', label='LA' if i==0 else \"\")\n",
    "    \n",
    "    axes[i, 2].set_title(f\"{view} {instant}\\nStructure Contours\", pad=10)\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Add legend only once\n",
    "    if i == 0:\n",
    "        axes[i, 2].legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Vision Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Convolutional block with batch norm and ReLU\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    \"\"\"Convert image to patches and embed with conv layers\"\"\"\n",
    "    def __init__(self, in_channels=1, embed_dim=128, patch_size=16):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            ConvBlock(in_channels, embed_dim//4, 7, 3),\n",
    "            ConvBlock(embed_dim//4, embed_dim//2, 3, 1),\n",
    "            ConvBlock(embed_dim//2, embed_dim, 3, 1),\n",
    "            nn.MaxPool2d(kernel_size=patch_size//8, stride=patch_size//8)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # [B, C, H, W] -> [B, embed_dim, H', W']\n",
    "        return rearrange(x, 'b c h w -> b (h w) c')  # Flatten to sequence\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Transformer block with multi-head attention\"\"\"\n",
    "    def __init__(self, embed_dim, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim*4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim*4, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Self-attention\n",
    "        res = x\n",
    "        x = self.norm1(x)\n",
    "        x, _ = self.attn(x, x, x)\n",
    "        x = res + x\n",
    "        \n",
    "        # MLP\n",
    "        res = x\n",
    "        x = self.norm2(x)\n",
    "        x = res + self.mlp(x)\n",
    "        return x\n",
    "\n",
    "class CVT(nn.Module):\n",
    "    \"\"\"Convolutional Visual Transformer for cardiac segmentation\"\"\"\n",
    "    def __init__(self, in_channels=1, num_classes=3, embed_dim=128, \n",
    "                 num_heads=4, num_layers=4, patch_size=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Patch embedding with convs\n",
    "        self.patch_embed = PatchEmbedding(in_channels, embed_dim, patch_size)\n",
    "        \n",
    "        # 2. Transformer encoder\n",
    "        self.transformer = nn.Sequential(*[\n",
    "            TransformerBlock(embed_dim, num_heads) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # 3. Decoder with transposed convs\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(embed_dim, embed_dim//2, 4, 2, 1),\n",
    "            ConvBlock(embed_dim//2, embed_dim//4),\n",
    "            nn.ConvTranspose2d(embed_dim//4, embed_dim//8, 4, 2, 1),\n",
    "            ConvBlock(embed_dim//8, embed_dim//16),\n",
    "            nn.Conv2d(embed_dim//16, num_classes, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # 1. Encode with conv + transformer\n",
    "        x = self.patch_embed(x)  # [B, N, embed_dim]\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # 2. Reshape back to spatial\n",
    "        h, w = H // self.patch_embed.proj[-1].stride, W // self.patch_embed.proj[-1].stride\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=h, w=w)\n",
    "        \n",
    "        # 3. Decode with transposed convs\n",
    "        x = self.decoder(x)\n",
    "        x = F.interpolate(x, size=(H, W), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# 1. Ultrasound Image Loading Functions (from your earlier code)\n",
    "def load_echo_image(patient_dir, patient_name, view, instant):\n",
    "    \"\"\"Load original echocardiographic image\"\"\"\n",
    "    img_path = patient_dir / f\"{patient_name}_{view}_{instant}.nii.gz\"\n",
    "    img = sitk.ReadImage(str(img_path))\n",
    "    return sitk.GetArrayFromImage(img).squeeze()\n",
    "\n",
    "# 2. Modified Cardiac Dataset Class\n",
    "class CardiacDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, view=\"2CH\", instant=\"ED\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Directory with patient folders\n",
    "            transform: Optional transform\n",
    "            view: View to load ('2CH' or '4CH')\n",
    "            instant: Cardiac phase ('ED' or 'ES')\n",
    "        \"\"\"\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.patient_dirs = sorted([d for d in self.root_dir.iterdir() if d.is_dir()])\n",
    "        self.transform = transform\n",
    "        self.view = view\n",
    "        self.instant = instant\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.patient_dirs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patient_dir = self.patient_dirs[idx]\n",
    "        patient_name = patient_dir.name\n",
    "        \n",
    "        # Load ultrasound image\n",
    "        img = load_echo_image(patient_dir, patient_name, self.view, self.instant)\n",
    "        \n",
    "        # Load corresponding mask\n",
    "        mask_path = patient_dir / f\"{patient_name}_{self.view}_{self.instant}_gt.nii.gz\"\n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(str(mask_path))).squeeze()\n",
    "        \n",
    "        # Convert to tensors\n",
    "        img = torch.FloatTensor(img).unsqueeze(0)  # Add channel dim [1, H, W]\n",
    "        mask = torch.LongTensor(mask)  # Class indices 0-3\n",
    "        \n",
    "        # Normalize image to [0, 1]\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, mask\n",
    "\n",
    "# 3. Training Setup with Ultrasound-specific Parameters\n",
    "def train_ultrasound_model(data_root):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Model with 4 output classes (background + 3 structures)\n",
    "    model = CVT(in_channels=1, num_classes=4).to(device)\n",
    "    \n",
    "    # Weighted loss (adjust based on your class distribution)\n",
    "    class_weights = torch.tensor([0.1, 1.0, 1.5, 1.0]).to(device)  # [bg, LVendo, LVepi, LA]\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Optimizer with lower learning rate for ultrasound\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    # Dataset and loader\n",
    "    train_dataset = CardiacDataset(\n",
    "        root_dir=data_root,\n",
    "        view=\"2CH\",\n",
    "        instant=\"ED\",\n",
    "        transform=None  # Add transforms if needed (e.g., RandomCrop)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, masks)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 4. Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your CAMUS dataset\n",
    "    database_nifti_root = \"./data\"  # Update with your path\n",
    "    \n",
    "    # Verify data loading\n",
    "    dataset = CardiacDataset(database_nifti_root)\n",
    "    img, mask = dataset[0]\n",
    "    print(f\"Image shape: {img.shape}, Mask shape: {mask.shape}\")\n",
    "    print(f\"Unique mask values: {torch.unique(mask)}\")  # Should be 0,1,2,3\n",
    "    \n",
    "    # Train model\n",
    "    model = train_ultrasound_model(database_nifti_root)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), \"cvt_ultrasound_segmentation.pth\")\n",
    "    # 1. Create model\n",
    "    model = CVT(in_channels=1, num_classes=3)\n",
    "    \n",
    "    # 2. Create dummy input (batch of 1, 1 channel, 256x256)\n",
    "    x = torch.randn(1, 1, 256, 256)\n",
    "    \n",
    "    # 3. Forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "    \n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")  # Should be [1, 3, 256, 256]import nump as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, dataset, device, num_samples=3):\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_samples, 5, figsize=(20, 4*num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            # Get random sample\n",
    "            idx = np.random.randint(len(dataset))\n",
    "            img, true_mask = dataset[idx]\n",
    "            img = img.unsqueeze(0).to(device)\n",
    "            \n",
    "            # Predict\n",
    "            pred_logits = model(img)\n",
    "            pred_mask = torch.argmax(pred_logits, dim=1).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Original data\n",
    "            original_img = img.squeeze().cpu().numpy()\n",
    "            true_mask = true_mask.numpy()\n",
    "            \n",
    "            # Plotting\n",
    "            axes[i, 0].imshow(original_img, cmap='gray')\n",
    "            axes[i, 0].set_title(\"Original Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground Truth\n",
    "            axes[i, 1].imshow(true_mask, cmap='jet', vmin=0, vmax=3)\n",
    "            axes[i, 1].set_title(\"Ground Truth\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Prediction\n",
    "            axes[i, 2].imshow(pred_mask, cmap='jet', vmin=0, vmax=3)\n",
    "            axes[i, 2].set_title(\"Prediction\")\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Individual Class Comparisons\n",
    "            for class_idx, class_name in enumerate([\"LVendo\", \"LVepi\", \"LA\"], start=1):\n",
    "                axes[i, class_idx+2].imshow(original_img, cmap='gray')\n",
    "                axes[i, class_idx+2].imshow(\n",
    "                    np.ma.masked_where(pred_mask != class_idx, pred_mask), \n",
    "                    cmap='autumn', alpha=0.5, vmin=0, vmax=3\n",
    "                )\n",
    "                axes[i, class_idx+2].imshow(\n",
    "                    np.ma.masked_where(true_mask != class_idx, true_mask), \n",
    "                    cmap='winter', alpha=0.3, vmin=0, vmax=3\n",
    "                )\n",
    "                axes[i, class_idx+2].set_title(f\"{class_name}\\nRed=Pred, Blue=GT\")\n",
    "                axes[i, class_idx+2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Quantitative Metrics\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    for img, true_mask in DataLoader(dataset, batch_size=8):\n",
    "        pred_mask = torch.argmax(model(img.to(device)), dim=1)\n",
    "        all_true.append(true_mask.flatten())\n",
    "        all_pred.append(pred_mask.cpu().flatten())\n",
    "    \n",
    "    all_true = torch.cat(all_true).numpy()\n",
    "    all_pred = torch.cat(all_pred).numpy()\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_pred, labels=[0,1,2,3]))\n",
    "    \n",
    "    print(\"\\nF1 Scores:\")\n",
    "    for i, name in enumerate([\"Background\", \"LVendo\", \"LVepi\", \"LA\"]):\n",
    "        print(f\"{name}: {f1_score(all_true==i, all_pred==i):.3f}\")\n",
    "\n",
    "# Usage\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CVT().to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))  # Load trained weights\n",
    "dataset = CardiacDataset(database_nifti_root)\n",
    "\n",
    "validate_model(model, dataset, device, num_samples=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE538",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
